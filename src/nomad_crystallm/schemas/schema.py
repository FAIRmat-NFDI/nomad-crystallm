import os

import pandas as pd
from ase.io import read
from ase.spacegroup import Spacegroup
from matid import SymmetryAnalyzer
from nomad.actions.utils import get_action_status, start_action
from nomad.datamodel.data import ArchiveSection, EntryData, EntryDataCategory
from nomad.datamodel.metainfo.annotations import (
    BrowserAnnotation,
    ELNAnnotation,
    ELNComponentEnum,
    SectionProperties,
)
from nomad.datamodel.results import Material, Results, SymmetryNew, System
from nomad.metainfo import Category, MEnum, Quantity, SchemaPackage, Section, SubSection
from nomad.normalizing.common import nomad_atoms_from_ase_atoms
from nomad.normalizing.topology import add_system, add_system_info
from pymatgen.core import Composition

from nomad_crystallm.actions.shared import (
    InferenceSettingsInput,
    InferenceUserInput,
    PromptConstructionInput,
)
from nomad_crystallm.schemas.utils import get_reference_from_mainfile

SPACE_GROUPS = [Spacegroup(i).symbol for i in range(1, 231)]

m_package = SchemaPackage()


class ActionCategory(EntryDataCategory):
    """
    Category for schemas that can be used to run NOMAD Actions from ELN interface.
    """

    m_def = Category(
        label='Run NOMAD Actions from ELN',
        categories=[EntryDataCategory],
    )


class InferenceSettings(ArchiveSection):
    """Settings for CrystaLLM inference actions."""

    model = Quantity(
        type=MEnum(
            [
                'crystallm_v1_small',
                'crystallm_v1_large',
            ]
        ),
        description="""
        Model used for inference.
        | Available models                                 | Description                                                                         |
        |--------------------------------------------------|-------------------------------------------------------------------------------------|
        | **crystallm_v1_small  (25.36M parameters)**      | Downloadable at https://zenodo.org/records/10642388/files/crystallm_v1_small.tar.gz |
        | **crystallm_v1_large  (1.2B parameters)**        | Downloadable at https://zenodo.org/records/10642388/files/crystallm_v1_large.tar.gz |
        """,  # noqa: E501
    )
    num_samples = Quantity(
        type=int,
        description='Number of samples to draw during inference.',
    )
    max_new_tokens = Quantity(
        type=int,
        description='Maximum number of tokens to generate in each sample.',
    )
    temperature = Quantity(
        type=float,
        description='Controls the randomness of predictions. Lower values make the '
        'model more deterministic, while higher values increase randomness.',
    )
    top_k = Quantity(
        type=int,
        description='Retain only the top_k most likely tokens, clamp others to have 0 '
        'probability.',
    )
    seed = Quantity(
        type=int,
        description='Random seed for reproducibility.',
    )
    dtype = Quantity(
        type=MEnum(['float32', 'bfloat16', 'float16']),
        description='Data type for the model (e.g., "float32", "bfloat16", "float16").',
    )
    compile = Quantity(
        type=bool,
        description='Whether to compile the model for faster inference.',
    )


class CrystaLLMInferenceResult(EntryData):
    """Result of a CrystaLLM inference action."""

    m_def = Section(
        label='CrystaLLM Inference Result',
        a_eln=ELNAnnotation(
            properties=SectionProperties(
                order=[
                    'prompt',
                    'action_id',
                    'status',
                    'generated_cifs',
                    'generated_structures',
                    'inference_settings',
                ]
            ),
        ),
    )
    prompt = Quantity(
        type=str,
        description='Prompt to be used for inference.',
    )
    action_instance_id = Quantity(
        type=str,
        description='ID of the inference action.',
    )
    generated_cifs = Quantity(
        type=str,
        shape=['*'],
        description='Path to the CIF generated by the LLM.',
    )
    generated_structures = Quantity(
        type=System,
        shape=['*'],
        description='Reference to the system normalized based on the generated CIF.',
    )
    inference_settings = SubSection(
        section_def=InferenceSettings,
        description='Settings used for the inference action.',
    )

    def process_generated_cifs(self, archive, logger):
        """
        Process the generated CIFs in `archive.data` and populates
        `archive.results.material`.
        """
        if not self.generated_cifs:
            return
        elements = set()
        topologies = {}
        system_references = []
        for cif in self.generated_cifs:
            if not cif:
                continue
            with archive.m_context.raw_file(cif) as file:
                try:
                    ase_atoms = read(file.name)
                except Exception as e:
                    logger.error(f'Unable to read cif: {cif}. Encounter the error: {e}')
                    continue
            # populate elements from a set of all the elements in ase_atoms
            elements.update(ase_atoms.get_chemical_symbols())
            symmetry = SymmetryNew()
            symmetry_analyzer = SymmetryAnalyzer(ase_atoms, symmetry_tol=1)
            symmetry.bravais_lattice = symmetry_analyzer.get_bravais_lattice()
            symmetry.space_group_number = symmetry_analyzer.get_space_group_number()
            symmetry.space_group_symbol = (
                symmetry_analyzer.get_space_group_international_short()
            )
            symmetry.crystal_system = symmetry_analyzer.get_crystal_system()
            symmetry.point_group = symmetry_analyzer.get_point_group()

            label = f'{ase_atoms.get_chemical_formula()}-{symmetry.space_group_number}'
            system = System(
                atoms=nomad_atoms_from_ase_atoms(ase_atoms),
                label=label,
                description='Structure generated by CrystaLLM with action_id: '
                f'"{self.action_instance_id}"',
                structural_type='bulk',
                dimensionality='3D',
                symmetry=symmetry,
            )
            add_system_info(system, topologies)
            add_system(system, topologies)

            # `system.system_id` is same as the reference to the topology index
            # `#/results/material/topology/{topology_iter}`
            system_references.append(f'#/{system.system_id}')
        self.generated_structures = system_references

        # reset results
        archive.results = Results(material=Material())
        archive.results.material.elements = list(elements)
        archive.results.material.topology = list(topologies.values())

    def normalize(self, archive, logger=None):
        """Normalize the section to ensure it is ready for processing."""
        self.process_generated_cifs(archive, logger)

        super().normalize(archive, logger)


class InferenceSettingsForm(ArchiveSection):
    """Settings used for CrystaLLM inference action with editable fields."""

    model = InferenceSettings.model.m_copy(deep=True)
    model.default = 'crystallm_v1_small'
    model.m_annotations['eln'] = ELNAnnotation(
        component=ELNComponentEnum.EnumEditQuantity,
    )

    num_samples = InferenceSettings.num_samples.m_copy(deep=True)
    num_samples.default = 1
    num_samples.m_annotations['eln'] = ELNAnnotation(
        component=ELNComponentEnum.NumberEditQuantity,
    )

    max_new_tokens = InferenceSettings.max_new_tokens.m_copy(deep=True)
    max_new_tokens.default = 3000
    max_new_tokens.m_annotations['eln'] = ELNAnnotation(
        component=ELNComponentEnum.NumberEditQuantity,
    )

    temperature = InferenceSettings.temperature.m_copy(deep=True)
    temperature.default = 0.8
    temperature.m_annotations['eln'] = ELNAnnotation(
        component=ELNComponentEnum.NumberEditQuantity,
    )

    top_k = InferenceSettings.top_k.m_copy(deep=True)
    top_k.default = 10
    top_k.m_annotations['eln'] = ELNAnnotation(
        component=ELNComponentEnum.NumberEditQuantity,
    )

    seed = InferenceSettings.seed.m_copy(deep=True)
    seed.default = 1337
    seed.m_annotations['eln'] = ELNAnnotation(
        component=ELNComponentEnum.NumberEditQuantity,
    )

    dtype = InferenceSettings.dtype.m_copy(deep=True)
    dtype.default = 'bfloat16'
    dtype.m_annotations['eln'] = ELNAnnotation(
        component=ELNComponentEnum.EnumEditQuantity,
    )

    compile = InferenceSettings.compile.m_copy(deep=True)
    compile.default = False
    compile.m_annotations['eln'] = ELNAnnotation(
        component=ELNComponentEnum.BoolEditQuantity,
    )


class InferenceStatus(ArchiveSection):
    """Section to fetch the status of an inference action instance."""

    action_instance_id = Quantity(
        type=str,
        description='ID of the inference action instance.',
    )
    status = Quantity(
        type=str,
        description='Status of the inference action instance.',
    )
    generated_entry = Quantity(
        type=CrystaLLMInferenceResult,
        description='Reference to the generated entry after the action completes.',
    )
    trigger_get_action_status = Quantity(
        type=bool,
        default=False,
        description='Retrieves the status of the inference action using action ID.',
        a_eln=ELNAnnotation(
            component=ELNComponentEnum.ActionEditQuantity,
            label='Get Action Status',
        ),
    )

    def normalize(self, archive, logger=None):
        """Normalize the section to ensure it is ready for processing."""
        super().normalize(archive, logger)
        if (
            not self.status
            or self.status == 'RUNNING'
            or self.trigger_get_action_status
        ):
            try:
                status = get_action_status(
                    self.action_instance_id, archive.metadata.authors[0].user_id
                )
                if status:
                    self.status = status.name
            except Exception as e:
                logger.error(f'Error getting action status: {e}. ')
            finally:
                self.trigger_get_action_status = False
            if self.status == 'COMPLETED':
                reference = get_reference_from_mainfile(
                    archive.metadata.upload_id,
                    os.path.join(
                        self.action_instance_id, 'inference_result.archive.json'
                    ),
                )
                if not reference:
                    logger.error(
                        'Unable to set reference for the generated entry for '
                        f'action {self.action_instance_id}.'
                    )
                else:
                    self.generated_entry = reference


class PromptInput(ArchiveSection):
    """Inputs for generating a prompt."""

    composition = Quantity(
        type=str,
        description='Chemical composition to be used for prompt. For example, NaCl, '
        'Al2O3.',
        a_eln=ELNAnnotation(component=ELNComponentEnum.StringEditQuantity),
    )
    num_formula_units_per_cell = Quantity(
        type=MEnum(['1', '2', '3', '4', '6', '8']),
        default='',
        description='(Optional) Number of formula units per unit cell to be used for '
        'prompt.',
        a_eln=ELNAnnotation(component=ELNComponentEnum.AutocompleteEditQuantity),
    )
    space_group = Quantity(
        type=MEnum(SPACE_GROUPS),
        default='',
        description='(Optional) Space group to be used for prompt.',
        a_eln=ELNAnnotation(component=ELNComponentEnum.AutocompleteEditQuantity),
    )


class CrystaLLMInferenceForm(EntryData):
    """Inference form for running CrystaLLM inference actions."""

    m_def = Section(
        label='CrystaLLM Inference Form',
        categories=[ActionCategory],
        description='Form to run CrystaLLM inference actions from the ELN interface.',
    )
    prompts_data_file = Quantity(
        type=str,
        description='Path to a CSV file containing multiple prompt generation inputs. '
        'The first line should be the header containing the column names: composition, '
        'num_formula_units_per_cell, space_group. Each subsequent line should be '
        'formatted as: <composition>, <num_formula_units_per_cell>, <space_group>. '
        'The composition field is required, while the other two are optional.',
        a_eln=ELNAnnotation(component=ELNComponentEnum.FileEditQuantity),
        a_browser=BrowserAnnotation(adaptor='RawFileAdaptor'),
    )
    trigger_run_action = Quantity(
        type=bool,
        description='Triggers the action defined under `run_action` method.',
        a_eln=ELNAnnotation(
            component=ELNComponentEnum.ActionEditQuantity,
            label='Run Inference Action',
        ),
    )
    prompt_inputs = SubSection(
        section_def=PromptInput,
        description='List of prompt generation inputs.',
        repeats=True,
    )
    inference_settings = SubSection(
        section_def=InferenceSettingsForm,
        description='Settings for the CrystaLLM inference action.',
    )
    triggered_inferences = SubSection(
        section_def=InferenceStatus,
        description='A section for storing the status of the triggered inference '
        'action.',
        repeats=True,
    )

    def run_action(self, archive, logger):
        """
        Run the CrystaLLM inference action with the provided archive.
        Uses the first author's credentials to run the action.
        """
        if not self.prompt_inputs:
            logger.warn(
                'No prompt inputs provided for the CrystaLLM inference action. '
                'Cannot run the action.'
            )
            return
        if not self.inference_settings:
            self.inference_settings = InferenceSettingsForm()
        prompt_construction_inputs = []
        for prompt in self.prompt_inputs:
            try:
                Composition(prompt.composition, strict=True)
            except Exception as e:
                logger.error(f'Invalid composition "{prompt.composition}": {e}')
                return
            prompt_construction_inputs.append(
                PromptConstructionInput(
                    composition=prompt.composition,
                    num_formula_units_per_cell=prompt.num_formula_units_per_cell,
                    space_group=prompt.space_group,
                )
            )
        inference_settings = InferenceSettingsInput(
            model=self.inference_settings.model,
            num_samples=self.inference_settings.num_samples,
            max_new_tokens=self.inference_settings.max_new_tokens,
            temperature=self.inference_settings.temperature,
            top_k=self.inference_settings.top_k,
            seed=self.inference_settings.seed,
            dtype=self.inference_settings.dtype,
            compile=self.inference_settings.compile,
        )
        input_data = InferenceUserInput(
            user_id=archive.metadata.authors[0].user_id,
            upload_id=archive.metadata.upload_id,
            prompt_construction_inputs=prompt_construction_inputs,
            inference_settings=inference_settings,
        )
        # validate input data before triggering action
        input_data.model_validate(input_data.model_dump())

        action_instance_id = start_action(
            action_id='nomad_crystallm.actions:crystallm_inference', data=input_data
        )

        inference_status = InferenceStatus(action_instance_id=action_instance_id)
        inference_status.normalize(archive, logger)
        if not self.triggered_inferences:
            self.triggered_inferences = [inference_status]
        else:
            self.triggered_inferences.append(inference_status)

    def read_prompt_inputs_from_file(self, archive, logger) -> list[PromptInput]:
        """
        Reads prompt inputs from a CSV file specified in `prompts_data_file`.
        The CSV file should have the following columns:
        - composition
        - num_formula_units_per_cell
        - space_group
        The `composition` column is required, while the other two are optional.
        """
        if not self.prompts_data_file:
            return []

        with archive.m_context.raw_file(self.prompts_data_file) as f:
            df = pd.read_csv(f)

        required_columns = {
            'composition',
            'num_formula_units_per_cell',
            'space_group',
        }
        if not required_columns.issubset(df.columns):
            logger.error(
                f'CSV file must contain the following columns: {required_columns}. '
                f'Provided columns: {set(df.columns)}. Not reading prompt inputs from '
                f'file {self.prompts_data_file}.'
            )
            return []
        prompt_inputs = []
        for _, row in df.iterrows():
            if pd.isna(row['composition']):
                logger.error(
                    '`composition` cannot be empty in the CSV file. Not reading '
                    f'prompt inputs from file {self.prompts_data_file}.'
                )
                return []
            composition = str(row['composition'])
            num_formula_units_per_cell = (
                str(int(row['num_formula_units_per_cell']))
                if not pd.isna(row['num_formula_units_per_cell'])
                else ''
            )
            space_group = (
                str(row['space_group']) if not pd.isna(row['space_group']) else ''
            )
            prompt_inputs.append(
                PromptInput(
                    composition=composition,
                    num_formula_units_per_cell=num_formula_units_per_cell,
                    space_group=space_group,
                )
            )

        return prompt_inputs

    def filter_prompts(self, logger):
        """
        Filters out duplicate prompts.
        """
        if not self.prompt_inputs:
            return
        unique_prompts = {
            prompt.composition
            + prompt.num_formula_units_per_cell
            + prompt.space_group: prompt
            for prompt in self.prompt_inputs
            if prompt.composition
        }
        if len(unique_prompts) < len(self.prompt_inputs):
            logger.warn('Duplicate prompts found. Keeping only the unique ones.')
        self.prompt_inputs = list(unique_prompts.values())

    def normalize(self, archive, logger):
        """
        Sets a default for inference_settings if not provided and runs the action
        if trigger_run_action is True.
        """
        self.m_setdefault('inference_settings')
        if prompt_inputs_from_file := self.read_prompt_inputs_from_file(
            archive, logger
        ):
            self.prompt_inputs = prompt_inputs_from_file
        self.filter_prompts(logger)
        if self.trigger_run_action:
            try:
                self.run_action(archive, logger)
            except Exception as e:
                logger.error(f'Error running action: {e}. ')
            self.trigger_run_action = False
        super().normalize(archive, logger)
